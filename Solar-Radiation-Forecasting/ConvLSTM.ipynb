{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c67b64f",
      "metadata": {
        "id": "1c67b64f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import explained_variance_score,mean_squared_error,mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a64bcd",
      "metadata": {
        "id": "68a64bcd"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"weather_2017+2018_hourly.csv\")\n",
        "data_as_np = dataset.GHI.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af369b7",
      "metadata": {
        "id": "3af369b7"
      },
      "outputs": [],
      "source": [
        "def series_to_supervised(data_np,n_lags,n_outs):\n",
        "    samples = len(data_np)-(n_lags+n_outs-1)\n",
        "    Inputs = []\n",
        "    Targets = np.empty((samples,n_outs))\n",
        "    for i in range(samples):\n",
        "        step = i+n_lags\n",
        "        sample = data_np[i:step]\n",
        "        Inputs.append(sample)\n",
        "        label = data_np[step:(step+n_outs)]\n",
        "        j = 0\n",
        "        for a in label:\n",
        "            Targets[i,j] = a\n",
        "            j = j+1\n",
        "    return np.array(Inputs),Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675938cb",
      "metadata": {
        "id": "675938cb"
      },
      "outputs": [],
      "source": [
        "def plot_model_history(model_summary):\n",
        "    plt.plot(model_summary.history['loss'])\n",
        "    plt.plot(model_summary.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train','test'],loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3a5418",
      "metadata": {
        "id": "0c3a5418"
      },
      "outputs": [],
      "source": [
        "def rmse_error(pred,y):\n",
        "    return np.sqrt(mean_squared_error(pred,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa02f5a",
      "metadata": {
        "id": "1aa02f5a"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape,n_out,train_x,train_y,test_x,test_y,rate,filter):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters = filter, kernel_size=(1,2), activation='relu', input_shape= input_shape))\n",
        "    model.add(Flatten())\n",
        "\n",
        "  #  output layer\n",
        "    model.add(Dense(n_out))\n",
        "\n",
        "    cp1 = ModelCheckpoint('ConvLSTM/', save_best_only=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate = rate), metrics=[RootMeanSquaredError()])\n",
        "    model_summary = model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=50, batch_size=64, callbacks=[cp1])\n",
        "    plot_model_history(model_summary)\n",
        "\n",
        "    model = load_model('ConvLSTM/')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d9d84a",
      "metadata": {
        "id": "20d9d84a"
      },
      "outputs": [],
      "source": [
        "train_rmse_error, test_rmse_error, test_mae = 0,0,0\n",
        "data_np = data_as_np.reshape(-1,1)\n",
        "lags = [120,240]\n",
        "seqs = [5]\n",
        "filters = [64]\n",
        "learning_rate = [0.01,0.001,0.0001,0.00001]\n",
        "n_out = 24\n",
        "# Prepare data\n",
        "for n_lags in lags:\n",
        "    Inputs,Targets = series_to_supervised(data_np,n_lags,n_out)\n",
        "    for n_seq in seqs:\n",
        "        n_steps = int(n_lags/n_seq)\n",
        "        Inputs = Inputs.reshape((Inputs.shape[0],n_seq,1,n_steps,1))\n",
        "        Inputs_model, Targets_model = Inputs[:-10], Targets[:-10]\n",
        "        Inputs_plot, Targets_plot = Inputs[-10:], Targets[-10:]\n",
        "\n",
        "        no_samples = Targets_model.shape[0]\n",
        "        split = int(0.3 * no_samples)\n",
        "\n",
        "        input_shape = (n_seq,1,n_steps,1)\n",
        "\n",
        "        train_x,train_y = Inputs_model[:-split],Targets_model[:-split]\n",
        "        test_x,test_y = Inputs_model[-split:],Targets_model[-split:]\n",
        "        for filterr in filters:\n",
        "            for rate in learning_rate:\n",
        "                for _ in range(2):\n",
        "                    model = create_model(input_shape,n_out,train_x,train_y,test_x,test_y,rate,filterr)\n",
        "\n",
        "                    train_pred,test_pred = model.predict(train_x), model.predict(test_x)\n",
        "\n",
        "                    train_rmse_error += rmse_error(train_pred.flatten(),train_y.flatten())\n",
        "                    test_rmse_error += rmse_error(test_pred.flatten(),test_y.flatten())\n",
        "                    test_mae += mean_absolute_error(test_pred.flatten(),test_y.flatten())\n",
        "                with open(\"ConvLSTM.txt\",\"a\") as f:\n",
        "                    f.write(f\"{n_lags},{n_seq},{rate},{filterr},{train_rmse_error/2},{test_rmse_error/2},{test_mae/2}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}